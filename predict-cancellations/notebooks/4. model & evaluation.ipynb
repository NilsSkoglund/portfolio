{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:36.145959Z",
     "start_time": "2020-10-09T07:32:34.691315Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:36.614007Z",
     "start_time": "2020-10-09T07:32:36.145959Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"hotel_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "\n",
    "In this notebook we are primarily 1) finding the best performing model and 2) evaluating results. \n",
    "\n",
    "In addition to this I'm doing some ad hoc feature engineering and data-cleaning. This is not optimal for clarity and readability, however I'm under significant time contraint in this project and I found it more efficient to this in the same notebook so please pardon me :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"saving\" features that will not be included in training but used to evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:37.457612Z",
     "start_time": "2020-10-09T07:32:37.442147Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving features that i will remove from model but want to include in analysis of results\n",
    "# will later merge these with result table (merge/join on index)\n",
    "canceled_days = data.canceled_days.to_frame()\n",
    "arrival_date = data.arrival_date.to_frame()\n",
    "year_week = data.year_week.to_frame()\n",
    "year_mo = data.year_mo.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reducing cats for countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:39.105138Z",
     "start_time": "2020-10-09T07:32:38.832878Z"
    }
   },
   "outputs": [],
   "source": [
    "# temporary dataframe with value_counts for columns to create an \"other\" category for countries with less than 100 bookings\n",
    "data_temp = data.country.value_counts().to_frame()\n",
    "# list with all countries with less than 100 bookings\n",
    "country_lst = data_temp.loc[data_temp.country < 100].index.tolist()\n",
    "\n",
    "# function to replace countries in series with \"OTHER\", if less than 100 bookings for that country\n",
    "def other_country(x):\n",
    "    if x in country_lst:\n",
    "        return \"OTHER\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# apply function to series\n",
    "data.country = data.country.apply(other_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason for doing reducing cats for countries was that it caused problem when evaluating feature_importances. \n",
    "# Perhaps not a very good reason but I'm under time contraint and need to move on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing some num-cols to cat-cols\n",
    "\n",
    "features are categorical but saved as numbers. I'll change to cat and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:39.545182Z",
     "start_time": "2020-10-09T07:32:39.524215Z"
    }
   },
   "outputs": [],
   "source": [
    "data.agent = data.agent.astype(\"object\")\n",
    "data.company = data.company.astype(\"object\")\n",
    "# Should have been changed in data-cleaning but didn't pick up on this until now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cols to include in model, creating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:40.116914Z",
     "start_time": "2020-10-09T07:32:40.046389Z"
    }
   },
   "outputs": [],
   "source": [
    "# leaving out columns such as canceled_days since it only holds values for bookings that were canceled and thus...\n",
    "# ... wouldn't be realistic training info\n",
    "number_cols = ['is_canceled',\n",
    " 'lead_time',\n",
    " 'stays_in_weekend_nights',\n",
    " 'stays_in_week_nights',\n",
    " 'adults',\n",
    " 'children',\n",
    " 'babies',\n",
    " 'is_repeated_guest',\n",
    " 'previous_cancellations',\n",
    " 'previous_bookings_not_canceled',\n",
    " 'booking_changes',\n",
    " 'days_in_waiting_list',\n",
    " 'adr',\n",
    " 'required_car_parking_spaces',\n",
    " 'total_of_special_requests']\n",
    "\n",
    "# leaving out 2 columns [\"reservation_status\", \"reservation_status_date\"] \n",
    "# since we wont have this information in a real world setting\n",
    "categorical_cols = ['hotel', \n",
    "'arrival_date_month', \n",
    "'meal', \n",
    "'market_segment',\n",
    "'distribution_channel', \n",
    "'reserved_room_type', \n",
    "'assigned_room_type',\n",
    "'deposit_type', \n",
    "'customer_type',\n",
    "'country',\n",
    "'agent',\n",
    "'company']\n",
    "\n",
    "# new dataframe with selected cols\n",
    "data = data[number_cols + categorical_cols]\n",
    "\n",
    "# target variable and features\n",
    "target_col = \"is_canceled\"\n",
    "X = data.drop(target_col, axis = 1)\n",
    "y = data[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: dropping columns that are causing problems\n",
    "\n",
    "Iterative process to find which columns are causing problems and if it's worth spending time trying to resolve it (which it would be if you think the add much explanatory value, otherwise it's probably not worth it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:40.976183Z",
     "start_time": "2020-10-09T07:32:40.876470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel 2\n",
      "arrival_date_month 12\n",
      "meal 5\n",
      "market_segment 8\n",
      "distribution_channel 5\n",
      "reserved_room_type 10\n",
      "assigned_room_type 12\n",
      "deposit_type 3\n",
      "customer_type 4\n",
      "country 39\n",
      "agent 333\n",
      "company 352\n"
     ]
    }
   ],
   "source": [
    "# Looking at number of categories for non-numeric features\n",
    "# This helps me get a feel for which columns might cause problems \n",
    "for x in data.select_dtypes(\"object\"):\n",
    "    print(x, data[x].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:41.397343Z",
     "start_time": "2020-10-09T07:32:41.364422Z"
    }
   },
   "outputs": [],
   "source": [
    "# company and agent where causing some issues and didn't seem to add much explanatory value so I'm dropping them\n",
    "X.drop([\"company\", \"agent\"], axis = 1, inplace = True)\n",
    "\n",
    "# this is possible loss of important information. For instance could be the case that there are meaningful differences in...\n",
    "# ... cancelation-rate for different companies.\n",
    "# However I'm under significant time contraint in this project and I feel ok dropping these in order to be able to move on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:32:42.639927Z",
     "start_time": "2020-10-09T07:32:42.181874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports for preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imports for model-evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "# Importing classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Selecting numeric features from X\n",
    "numeric_features = X.select_dtypes(\"number\").columns\n",
    "# Transformation-pipeline for numeric features (scaler and imputer)\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                     ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "# Selecting categorical features from X\n",
    "categorical_features = X.select_dtypes(\"object\").columns\n",
    "# Transformation-Pipeline for categorical features (imputer and onehotencoder)\n",
    "categorical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy = \"constant\")),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown = \"ignore\"))])\n",
    "\n",
    "# Columntransformer(final preprocessing pipeline). Incorporates transformation-pipelines for both num- and cat-features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T07:46:46.025008Z",
     "start_time": "2020-10-09T07:32:45.710054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8819415407779567\n",
      "<function _passthrough_scorer at 0x0000023A357D2790>\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# preprocessing pipeline same as before, now only using the best performing model (RandomForest)\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Fake param_grid since I wan't to use default settings cause they had the best performance...\n",
    "# .. and I don't want to have a slow runtime for this cell when i'm running through it when making minor adjustments\n",
    "param_grid = {\n",
    "    #\"classifier__criterion\": [\"gini\"]\n",
    "    #,'classifier__max_depth': [None]\n",
    "    #,\"classifier__n_estimators\": [100]\n",
    "}\n",
    "\n",
    "# Fake GridSearchCV because param_grid is fake\n",
    "# 5 cross-folds\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Fitting model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output to evaluate\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.scorer_)\n",
    "print(grid_search.best_params_)\n",
    "results = grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:12:04.899108Z",
     "start_time": "2020-10-16T12:12:04.891541Z"
    }
   },
   "outputs": [],
   "source": [
    "# 88% accuracy. Baseline would be around 60 %. Good performance. Suspiciously good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:00:51.052941Z",
     "start_time": "2020-10-09T08:00:50.302039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14078   915]\n",
      " [ 1778  7107]]\n",
      "ACC: 0.8872183599966497\n",
      "P: 0.8859386686611818\n",
      "R: 0.7998874507597074\n"
     ]
    }
   ],
   "source": [
    "# Importing metrics for model evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# creating classifier from best_estimator_ from the grid-search\n",
    "clf = grid_search.best_estimator_\n",
    "\n",
    "# predictions for X_test\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "print(\"ACC:\", accuracy_score(y_test, test_pred))\n",
    "print(\"P:\", precision_score(y_test, test_pred))\n",
    "print(\"R:\", recall_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significanly higher precision compared to recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concats with features that wasn't allowed/included in training\n",
    "\n",
    "I wan't to concat these features to result-table to allow for more in depth-analysis\n",
    "\n",
    "features are:\n",
    "\n",
    "canceled_days = data.canceled_days.to_frame() > I'll be able to see distribution of cancellations\\ \n",
    "arrival_date = data.arrival_date.to_frame() > I'll be able to see if there are differences between time-periods\\\n",
    "year_week = data.year_week.to_frame()\\\n",
    "year_mo = data.year_mo.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concat test with canceled_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:36.668010Z",
     "start_time": "2020-10-09T08:01:36.657031Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of dataframes to concat\n",
    "objs = [X_test, canceled_days, arrival_date, year_week, year_mo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:36.901890Z",
     "start_time": "2020-10-09T08:01:36.859000Z"
    }
   },
   "outputs": [],
   "source": [
    "# concatinating on index\n",
    "test_evaluation = pd.concat(objs, axis=1, join='inner', ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add true and pred to df and create cm-col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:15:12.135131Z",
     "start_time": "2020-10-16T12:15:12.131146Z"
    }
   },
   "outputs": [],
   "source": [
    "# test predictions to evaluation df\n",
    "test_evaluation[\"y_true\"] = y_test\n",
    "\n",
    "# true outcome to evaluation df\n",
    "test_evaluation[\"y_pred\"] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:37.604102Z",
     "start_time": "2020-10-09T08:01:37.541838Z"
    }
   },
   "outputs": [],
   "source": [
    "# mashing pred and true \n",
    "test_evaluation[\"true_pred\"] = test_evaluation.y_true.astype(str) +\"-\"+ test_evaluation.y_pred.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:37.809791Z",
     "start_time": "2020-10-09T08:01:37.797821Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to get cm-values for mashed pred and true\n",
    "def cm(true_pred):\n",
    "    if true_pred == \"0-0\":\n",
    "        return \"TN\"\n",
    "    if true_pred == \"1-0\":\n",
    "        return \"FN\"\n",
    "    if true_pred == \"1-1\":\n",
    "        return \"TP\"\n",
    "    if true_pred == \"0-1\":\n",
    "        return \"FP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:38.929492Z",
     "start_time": "2020-10-09T08:01:38.906554Z"
    }
   },
   "outputs": [],
   "source": [
    "# applying function cm (cell above)\n",
    "test_evaluation.true_pred = test_evaluation.true_pred.apply(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancellations with less than 31 days notice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:41.116512Z",
     "start_time": "2020-10-09T08:01:41.101551Z"
    }
   },
   "outputs": [],
   "source": [
    "# mask to filter for bookings that were cancelled less than one month before arrival\n",
    "mask1 = test_evaluation.canceled_days < 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:01:43.666530Z",
     "start_time": "2020-10-09T08:01:43.641567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4004\n",
       "Name: y_true, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4004 bookings were canceled less than one month(31 days) before arrival in test-data\n",
    "test_evaluation.loc[mask1].y_true.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:19:16.337223Z",
     "start_time": "2020-10-16T12:19:16.316195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1691933997822263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 23878 was total no. of rows in test-data so ~16.9% of total bookings were canceled less than 31 days before arrival\n",
    "4040/23878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:02:18.574411Z",
     "start_time": "2020-10-09T08:02:18.551951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2792\n",
       "0    1212\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions from model \n",
    "test_evaluation.loc[mask1].y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:02:33.650515Z",
     "start_time": "2020-10-09T08:02:33.636554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6973026973026973"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision for model.\n",
    "2792/4004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the models precision for total data was ~ 88.6% but less than 70% for cancellations made less than 31 days before arrival\n",
    "# Significat difference! Model is not nearly as good at predicting cancellations made close to arrival\n",
    "# This is of course not good for our business use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with predict proba for specified threshold\n",
    "\n",
    "1) Looking at predictions made with 0.9 or above probability\n",
    "\n",
    "2) Looking at positive predictions made within 30 days of cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:03:48.301453Z",
     "start_time": "2020-10-09T08:03:47.597636Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding models prediction probability for \"1\"(true) prediction to evaluation df\n",
    "test_evaluation[\"proba_1\"] = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:03:48.723773Z",
     "start_time": "2020-10-09T08:03:48.704820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TP    0.992175\n",
       "FP    0.007825\n",
       "Name: true_pred, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So when models prediction probability is > 0.9 we have precision over 99%!\n",
    "test_evaluation.loc[test_evaluation.proba_1 > 0.9].true_pred.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many useful predictions is the model making and with that precision? \n",
    "\n",
    "In order to find out if the model is useful in a real world setting I'm interested in 2 numbers: \n",
    "1) How many actionable predictions is the model making?\\\n",
    "2) With what precision is the \"actionable\" predictions being made? \n",
    "\n",
    "An actionable prediction I will define as:\n",
    "1) a prediction made with > 0.9 prediction probability (predict_proba)\\\n",
    "2) a prediction made about a booking that canceled 30 days or less before arrival\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:04:25.594367Z",
     "start_time": "2020-10-09T08:04:25.587387Z"
    }
   },
   "outputs": [],
   "source": [
    "# df with test evaluation. Only when predict_proba for \"true\" (cancellation) > 0.9\n",
    "proba_90 = test_evaluation.loc[test_evaluation.proba_1 > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:04:26.013401Z",
     "start_time": "2020-10-09T08:04:25.993457Z"
    }
   },
   "outputs": [],
   "source": [
    "# index in proba_90 where canceled_days is more than 30\n",
    "index_canceled_days_above_30 = proba_90.loc[proba_90.canceled_days > 30].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:58:32.960103Z",
     "start_time": "2020-10-16T12:58:32.953122Z"
    }
   },
   "outputs": [],
   "source": [
    "# new column where we drop rows where canceled days is more than 30. \n",
    "# This df only contains:\n",
    "    # 1) predictions made for cancellations with more than 0.9 probability \n",
    "    # 2) predictions made for bookings that canceled less than 30 days before arrival\n",
    "proba_90_clean = proba_90.drop(index_canceled_days_above_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T08:04:26.700205Z",
     "start_time": "2020-10-09T08:04:26.692227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1473\n",
       "0      35\n",
       "Name: y_true, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at y_true(true outcomes) for predictions made with proba > 0.9 and canceled_days < 31\n",
    "proba_90_clean.y_true.value_counts()\n",
    "\n",
    "# If predict proba is > 0.9 the model will have made a prediction that the booking is canceled (1/True)\n",
    "# ... so comparing with true outcome gives us precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T12:59:03.239683Z",
     "start_time": "2020-10-16T12:59:03.221723Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976790450928382"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision is ~ 97.7% for model \n",
    "1473/(1473+35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T13:11:07.704146Z",
     "start_time": "2020-10-16T13:11:07.696162Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06315436803752408"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and whe are making useful predictions for ~6% of data\n",
    "1508/23878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We are making actionable predictions for ~ 6% of the bookings and these predictions have in a test-environment achieved a precision of ~97.7%. \n",
    "\n",
    "There is definitely a possible profitable use-case for such a model. To evaluate this we could look at:\n",
    "- loss/profit for FP/TP based on models precision to get an expected average value for each actionable prediction\n",
    "- cost for building and maintaing model\n",
    "- no. of actionable predictions that has to made to make up for costs related to model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
