{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imp libs and get csv with streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:35:12.081507Z",
     "start_time": "2020-09-15T15:35:11.444115Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "I´m using the info from the csv created in \"1. Sthlm - Get info_sold_sthlm\"\n",
    "\n",
    "I´m scraping info from 1273 streets in Stockholms kommun \n",
    "\n",
    "This gives me the raw data for the analysis (50k+ sold apartments in Sthlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:43:39.514740Z",
     "start_time": "2020-09-15T15:43:39.491516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading csv with the streets I´m getting info from\n",
    "df = pd.read_csv(\"id_sold_sthlm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:43:39.968472Z",
     "start_time": "2020-09-15T15:43:39.963492Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create lst for looping \n",
    "lst_gator = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:38:01.685681Z",
     "start_time": "2020-09-15T15:38:01.670722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1273"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1273 streets with a varying number of apartments sold for each street\n",
    "# min = 0 for a street\n",
    "# max ~ 1000 for a street\n",
    "len(lst_gator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape info from Hemnet - Runtime 30-60 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T16:26:52.931990Z",
     "start_time": "2020-09-12T16:01:09.531831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize list to store information from each sold apartment\n",
    "adress_lst = []\n",
    "omrade_lst = []\n",
    "kvm_lst = []\n",
    "rum_lst = []\n",
    "maklare_lst = []\n",
    "avgift_lst = []\n",
    "slutpris_lst = []\n",
    "datum_lst = []\n",
    "change_lst = []\n",
    "gata_id_lst = []\n",
    "gata_lst = []\n",
    "stockholm_lst = []\n",
    "\n",
    "# Loop through the lst of 1273 apartments\n",
    "for i in lst_gator:\n",
    "    # Each street has a varying number of apartments sold\n",
    "    ## Hemnet displays 50 sold objects per page\n",
    "    ### page_num stores the number of times I'm looping through each street \n",
    "    #### This is possible since {street_id} and {page_number} are the only variables in the URL\n",
    "    page_num = math.ceil(int(i[0])/50)\n",
    "    for j in range(1, page_num+1):\n",
    "        url = f\"https://www.hemnet.se/salda/bostader?item_types%5B%5D=bostadsratt&location_ids%5B%5D={i[2]}&page={j}&sold_age=all\"\n",
    "        response = requests.get(url)\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, (\"lxml\"))\n",
    "        \n",
    "        # each container has all the desired info about one sold object\n",
    "        container = soup.select(\"li.sold-results__normal-hit\")\n",
    "\n",
    "        for x in container: \n",
    "            \n",
    "            # 1: I'm getting info from lst_gator (iterator = i)\n",
    "            \n",
    "            ## Get street ID \n",
    "            gata_id_lst.append(i[2])\n",
    "            \n",
    "            ## Get street name\n",
    "            gata = i[1]\n",
    "            gata_re = re.findall(r\"[-] +[A-Za-zåäöÅÄÖ\\s]+[,]\", gata)\n",
    "            if gata_re:                \n",
    "                gata_re_strip = gata_re[0].strip(\",-\").strip()\n",
    "                gata_lst.append(gata_re_strip)\n",
    "            else: \n",
    "                gata_lst.append(np.nan)\n",
    "            \n",
    "            ## Get municipality (should always be \"Stockholms kommun\")\n",
    "            if \"Stockholms kommun\" in i[1]:\n",
    "                stockholm_lst.append(\"Stockholms kommun\")\n",
    "            else:\n",
    "                stockholm_lst.append(np.nan)\n",
    "            \n",
    "            # 2: I'm getting info from the container (iterator = x)\n",
    "\n",
    "            ## Get adress\n",
    "            adress = [x.text for x in x.select(\"span.item-result-meta-attribute-is-bold\")]\n",
    "            if adress:\n",
    "                adress_lst.append(adress[0])\n",
    "            else:\n",
    "                adress.lst.append(np.nan)\n",
    "            \n",
    "            ## Get area (neighbourhood)\n",
    "            omr = [x.text for x in x.select(\"span.item-link\")]\n",
    "            if len(omr) == 1:\n",
    "                omrade_lst.append(np.nan)    \n",
    "            else:\n",
    "                omrade_lst.append(omr[1].strip())\n",
    "                \n",
    "            ## Get sqm\n",
    "            kvm = [re.findall(r\"(([\\d+,]+[\\d+])\\xa0m)\", x.text) for x in x.select(\"div.sold-property-listing__subheading.sold-property-listing--left\")]\n",
    "            if kvm[0]:\n",
    "                kvm_lst.append(kvm[0][0][1])\n",
    "            else:\n",
    "                kvm_lst.append(np.nan)     \n",
    "            \n",
    "            ## Get no. of rooms\n",
    "            rum = [re.findall(r\"(([ \\d+,]+[\\d+])\\xa0rum)\", x.text) for x in x.select(\"div.sold-property-listing__subheading.sold-property-listing--left\")]\n",
    "            if rum[0]:\n",
    "                rum_lst.append(rum[0][0][1].strip())\n",
    "            else:\n",
    "                rum_lst.append(np.nan)\n",
    "                \n",
    "            ## Get broker (firm)\n",
    "            maklare = [x.text.strip() for x in x.select(\"div.sold-property-listing__broker\")]\n",
    "            if maklare:\n",
    "                maklare_lst.append(maklare[0])\n",
    "            else:\n",
    "                maklare_lst.append(np.nan)\n",
    "                \n",
    "            ## Get monthly fee\n",
    "            avgift = [x.text.strip() for x in x.select(\"div.sold-property-listing__fee\")]\n",
    "            if len(avgift) == 1:\n",
    "                avgift = re.findall(\"[0-9]+\", avgift[0])\n",
    "                avgift_lst.append(\"\".join(avgift))\n",
    "            else: \n",
    "                avgift_lst.append(np.nan)\n",
    "                \n",
    "            ## Get final price\n",
    "            slutpris = [re.findall(\"[0-9]+\", x.text) for x in x.select(\"span.sold-property-listing__subheading\")]\n",
    "            if slutpris:\n",
    "                slutpris_lst.append(\"\".join(slutpris[0]))\n",
    "            else:\n",
    "                slutpris_lst.append(np.nan)\n",
    "                \n",
    "            ## Get date_sold\n",
    "            datum = [x.text.strip() for x in x.select(\"div.sold-property-listing__sold-date\")]\n",
    "            if datum:\n",
    "                datum_lst.append(datum[0])\n",
    "            else:\n",
    "                datum_lst.append(np.nan)\n",
    "                \n",
    "            ## Get % change in price\n",
    "            ## Here I'm using continue to handle special cases and therefore this has to be on the bottom of the loop\n",
    "            ## Otherwise continue would screw things up\n",
    "            change = [re.findall(\"[0-9+-]+\", x.text) for x in x.select(\"div.sold-property-listing__price-change\")]\n",
    "            if not change:\n",
    "                change_lst.append(0)\n",
    "                continue\n",
    "            if not change[0]:\n",
    "                change_lst.append(0)\n",
    "                continue\n",
    "            else:\n",
    "                change_lst.append(change[0][0])\n",
    "# Print len for all lists to verify that they have equal length                \n",
    "print(len(adress_lst))\n",
    "print(len(omrade_lst))\n",
    "print(len(kvm_lst))\n",
    "print(len(rum_lst))\n",
    "print(len(maklare_lst))\n",
    "print(len(avgift_lst))\n",
    "print(len(slutpris_lst))\n",
    "print(len(datum_lst))\n",
    "print(len(change_lst))\n",
    "print(len(gata_id_lst))\n",
    "print(len(gata_lst))\n",
    "print(len(stockholm_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip lists, create df and write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T16:32:48.936622Z",
     "start_time": "2020-09-12T16:32:48.902676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zip lists\n",
    "comp_lst = list(zip(adress_lst, omrade_lst, kvm_lst, rum_lst, maklare_lst,\n",
    "                    avgift_lst, slutpris_lst, datum_lst, change_lst, gata_id_lst, gata_lst, stockholm_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T16:32:52.153956Z",
     "start_time": "2020-09-12T16:32:52.032359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create df\n",
    "df_sold = pd.DataFrame(data = comp_lst, columns = [\"adress\", \"omrade\", \"kvm\", \"rum\",\n",
    "                                                  \"maklare\", \"avgift\", \"slutpris\", \"datum\",\n",
    "                                                    \"prisförändring\", \"gata_id_lst\", \"gata_lst\", \"stockholm_lst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T09:05:10.711241Z",
     "start_time": "2020-09-13T09:05:10.384558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write to csv\n",
    "df_sold.to_csv(\"sthlm_raw.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
